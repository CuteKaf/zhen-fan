<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Zhen Fan – Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="assets/css/styles.css">
</head>
<body>
<div class="main-container">

  <header class="site-header">
    <h1 class="site-title">Zhen Fan</h1>
    <div class="site-subtitle">
      M.Sc. graduate, National University of Singapore (NUS)<br>
      <strong>Simulation-Driven Multimodal Learning & Embodied Intelligence</strong>
    </div>
    <nav class="navbar">
      <a href="index.html" class="active">Home</a>
      <a href="research.html">Research</a>
      <a href="publications.html">Publications</a>
      <a href="projects.html">Projects</a>
      <a href="cv.html">CV</a>
      <a href="contact.html">Contact</a>
    </nav>
  </header>

  <section class="about-container">
    <div class="about-text">
      <h2>About Me</h2>
      <p>
        I am an M.Sc. graduate from the <strong>National University of Singapore (NUS)</strong> and a Digitalization Engineer focusing on <strong>simulation-driven multimodal learning</strong> for embodied intelligence.
      </p>

      <p>
        My work centers on building <strong>high-fidelity digital twins</strong>, <strong>world model–driven synthetic data pipelines</strong>, and <strong>multimodal perception systems</strong> to bridge the gap between virtual environments and real-world robotics.
      </p>

      <p>
        I work extensively with <strong>NVIDIA Omniverse (Isaac Sim)</strong> to develop industrial-grade Digital Twins and automated simulation workflows. 
        I also leverage <strong>NVIDIA COSMOS</strong> as a world model, integrating video generation and scene imagination into a scalable <strong>synthetic-data pipeline</strong> for VLM and action recognition training.
      </p>

      <p>
        I contributed to a <strong>Sim-to-Real action recognition framework</strong> that achieved <strong>90.31% accuracy</strong> in real-world factory validation, demonstrating the effectiveness of simulation-guided training in data-scarce industrial environments.
      </p>

      <p>
        Broadly, I am interested in combining simulation, multimodal models, and structured knowledge to improve generalization, safety, and interpretability in embodied agents. 
        My long-term goal is to extend these methods toward <strong>Human–Robot Collaboration (HRC)</strong>, enabling robots to learn complex and interactive behaviors in virtual environments before deployment.
      </p>
      
      <div style="margin-top: 25px; padding: 20px; background: #f8f9fa; border-radius: 8px; font-size: 0.95rem; border: 1px solid #eee;">
        <ul style="margin: 0; padding-left: 20px;">
          <li style="margin-bottom: 10px;">
            <strong>Simulation & Digital Twin:</strong> NVIDIA Omniverse (Isaac Sim), high-fidelity modeling, industrial scene reconstruction, asset binding.
          </li>
          <li style="margin-bottom: 10px;">
            <strong>World Models & Synthetic Data Generation:</strong> NVIDIA COSMOS world model (video generation, scene imagination), automated pipelines, domain randomization, large-scale dataset construction.
          </li>
          <li style="margin-bottom: 0;">
            <strong>Sim-to-Real Transfer:</strong> Contributed to a real-world validated action recognition system (<strong>90.31% accuracy</strong>), VLM training, synthetic-to-real generalization, reality gap reduction.
          </li>
        </ul>
      </div>

      <p style="margin-top: 24px;">
        <a href="projects.html" style="color: #2563eb; font-weight: 600; text-decoration: none;">View My Projects →</a>
      </p>
    </div>
    <div class="about-photo">
      <img src="assets/img/profile.jpg" alt="Zhen Fan">
    </div>
  </section>

  <section>
    <h2>News</h2>
    <ul>
      <li><strong>[2025.06]</strong> Graduating from NUS with an M.Sc. in Mechanical Engineering.</li>
      <li><strong>[2025.04]</strong> Paper <em>"Sim2Know: A Neuro-Symbolic Digital Twin Framework"</em> submitted to <strong>CIRP Annals</strong>.</li>
      <li><strong>[2025.01]</strong> Paper <em>"MetalMind: Cognitive Simulation for Industrial Knowledge Parsing"</em> submitted to <strong>npj Advanced Manufacturing</strong>.</li>
      <li><strong>[2024.10]</strong> Achieving 90.31% accuracy in Sim2Real Action Recognition using synthetic data.</li>
    </ul>
  </section>

</div>
</body>
</html>
