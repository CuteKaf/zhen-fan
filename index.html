<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Zhen Fan – Home</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="assets/css/styles.css">
  <style>
    /* 增加一点 Education 专属的简单样式，不需要改 css 文件也能生效 */
    .edu-item { margin-bottom: 12px; }
    .edu-school { font-weight: 700; color: #111; font-size: 1.05rem; }
    .edu-meta { color: #555; font-size: 0.95rem; }
  </style>
</head>
<body>
<div class="main-container">

  <header class="site-header">
    <h1 class="site-title">Zhen Fan</h1>
    <div class="site-subtitle">
      M.Sc. graduate, National University of Singapore (NUS)<br>
      <strong>Simulation-Driven Multimodal Learning & Embodied Intelligence</strong>
    </div>
    <nav class="navbar">
      <a href="index.html" class="active">Home</a>
      <a href="research.html">Research</a>
      <a href="publications.html">Publications</a>
      <a href="projects.html">Projects</a>
      <a href="cv.html">CV</a>
      <a href="contact.html">Contact</a>
    </nav>
  </header>

  <section class="about-container">
    <div class="about-text">
      <h2>About Me</h2>
      <p>
        I am an M.Sc. graduate from the <strong>National University of Singapore (NUS)</strong> and a Digitalization Engineer working on <strong>simulation-driven multimodal learning</strong> for embodied intelligence.
      </p>

      <p>
        My research focuses on <strong>high-fidelity Digital Twins</strong>, <strong>world-model-based synthetic data generation</strong>, and <strong>Sim-to-Real perception systems</strong> for industrial robotics.
      </p>

      <p>
        I work with <strong>NVIDIA Omniverse (Isaac Sim)</strong> and <strong>COSMOS</strong> to build scalable simulation pipelines, and I contributed to a Sim-to-Real action recognition framework validated at <strong>90.31% accuracy</strong> in a real factory environment.
      </p>

      <p>
        My broader research interest lies in combining simulation, multimodal models, and structured knowledge to enable explainable and safety-aware embodied AI, with long-term applications in <strong>Human–Robot Collaboration</strong>.
      </p>
      
      <p style="margin-top: 20px; color: #4b5563; font-size: 0.95rem;">
        <strong>Research Areas:</strong> Digital Twin · World Models · Knowledge Graph · Sim2Real · Multimodal Learning · Embodied AI
      </p>

      <p style="margin-top: 24px;">
        <a href="projects.html" style="color: #2563eb; font-weight: 600; text-decoration: none;">View My Projects →</a>
      </p>
    </div>
    <div class="about-photo">
      <img src="assets/img/profile.jpg" alt="Zhen Fan">
    </div>
  </section>

  <section>
    <h2>Education</h2>
    
    <div class="edu-item">
      <div class="edu-school">National University of Singapore (NUS)</div>
      <div class="edu-meta">M.Sc. in Mechanical Engineering (2024 – 2025)</div>
    </div>

    <div class="edu-item">
      <div class="edu-school">Beijing Jiaotong University (BJTU)</div>
      <div class="edu-meta">B.Eng. in Mechatronics Engineering (2020 – 2024)</div>
    </div>
  </section>

  <section>
    <h2>News</h2>
    <ul>
      <li><strong>[2025.06]</strong> Graduating from NUS with an M.Sc. in Mechanical Engineering.</li>
      <li><strong>[2025.04]</strong> Paper <em>"Sim2Know"</em> submitted to <strong>CIRP Annals</strong>.</li>
      <li><strong>[2025.01]</strong> Paper <em>"MetalMind"</em> submitted to <strong>npj Advanced Manufacturing</strong>.</li>
    </ul>
  </section>

</div>
</body>
</html>
